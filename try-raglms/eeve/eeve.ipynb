{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# pdfíŒŒì¼ ë¡œë“œ\n",
    "loader = PyPDFLoader(\"C:\\\\Users\\\\user240512\\\\Desktop\\\\í™©ì‹ ì •\\\\langchain\\\\pdf\\\\2018 ì¥ì• ì¸ ì°¨ë³„ ì˜ˆë°© ì‚¬ì´ë²„ì¸ê¶Œêµìœ¡ë³´ì¡°êµì¬.pdf\")\n",
    "#print(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¼ë¶€ í˜ì´ì§€ë§Œ ì„ íƒ\n",
    "sel_pages = pages[9:225]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ë¬¸ì„œë¥¼ ë¬¸ì¥ìœ¼ë¡œ ë¶„ë¦¬\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "docs = text_splitter.split_documents(sel_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user240512\\.conda\\envs\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user240512\\.conda\\envs\\langchain\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# í—ˆê¹…í˜ì´ìŠ¤ì— ì—…ë¡œë“œ ë˜ì–´ìˆëŠ” ì„ë² ë”© ëª¨ë¸ ì„ íƒ\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name='jhgan/ko-sroberta-multitask',\n",
    "    # model_kwargs={'device':'cpu'},\n",
    "    model_kwargs={'device':'cuda'},\n",
    "    encode_kwargs={'normalize_embeddings':True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created and persisted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user240512\\.conda\\envs\\langchain\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "from langchain.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œ ê²½ë¡œ ì„¤ì •\n",
    "vectorstore_path = 'vectorstore'\n",
    "os.makedirs(vectorstore_path, exist_ok=True)\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ì €ì¥\n",
    "vectorstore = Chroma.from_documents(docs, embeddings, persist_directory=vectorstore_path)\n",
    "\n",
    "# ë²¡í„°ìŠ¤í† ì–´ ë°ì´í„°ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥\n",
    "vectorstore.persist()\n",
    "print(\"Vectorstore created and persisted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Ollama ë¥¼ ì´ìš©í•´ ë¡œì»¬ì—ì„œ LLM ì‹¤í–‰\n",
    "model = ChatOllama(model=\"eeve\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='eeve', temperature=0.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ì‚¬í•œ kê°œì˜ ì²­í¬ \n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt í…œí”Œë¦¿ ìƒì„±\n",
    "template = f'''\"ì¹œì ˆí•œ ì±—ë´‡ìœ¼ë¡œì„œ ìƒëŒ€ë°©ì˜ ìš”ì²­ì— ìµœëŒ€í•œ ìì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µí•˜ì. \n",
    "ëª¨ë“  ëŒ€ë‹µì€ í•œêµ­ì–´(Korean)ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜. \n",
    "ë„ˆëŠ” ì‚¬ìš©ìì˜ ì…ë ¥ì— ëŒ€í•´ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì •ë³´ì „ë‹¬ ê²Œì‹œë¬¼ í˜•ì‹ìœ¼ë¡œ ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ì„ ìƒì„±í•´ì•¼ë¼\":\n",
    "{{context}}\n",
    "\n",
    "\n",
    "\n",
    "Question: {{question}}\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join([d.page_content for d in docs])\n",
    "\n",
    "# RAG Chain ì—°ê²°\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: ì¥ì•  ë“±ê¸‰ ê¸°ì¤€\n",
      "Answer: ğŸŒˆ ì¥ì•  ë“±ê¸‰ ê¸°ì¤€ ì´í•´í•˜ê¸° ğŸ’¡\n",
      "\n",
      "ì¥ì• ì¸ë³µì§€ë²•ìƒ í•œêµ­ì—ì„œ ì¸ì •í•˜ëŠ” ì¥ì• ìœ í˜•ì€ ì´ 15ê°€ì§€ì´ë©°, ê° ìœ í˜•ë³„ë¡œ íŒì • ê¸°ì¤€ì— ë”°ë¼ 1~6ê¸‰ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤. ì´ ë“±ê¸‰ì— ë”°ë¼ ì¥ì• ì¸ ì§€ì› ì œë„ê°€ ì œê³µë˜ëŠ”ë°, 1ê¸‰ì´ ê°€ì¥ ì¤‘ì¦ì´ê³  6ê¸‰ì´ ê²½ì¦ì…ë‹ˆë‹¤.\n",
      "\n",
      "ğŸŒ± ë°œë‹¬ì¥ì• : ì¸ì§€ì  ì–´ë ¤ì›€ ğŸ’¡\n",
      "ë°œë‹¬ì¥ì• ëŠ” ë§ ê·¸ëŒ€ë¡œ ë°œë‹¬ì— ì–´ë ¤ì›€ì„ ê²ªëŠ” ì¥ì• ë¡œ, ì§€ì  ì¥ì• ì™€ ìíì„± ì¥ì• ê°€ í¬í•¨ë©ë‹ˆë‹¤. ì´ ì¥ì• ë¥¼ ê°€ì§„ ì‚¬ëŒë“¤ì€ ë˜ë˜ì˜ ê°™ì€ ì—°ë ¹ì— ìˆëŠ” ì‚¬ëŒë“¤ê³¼ ë¹„êµí•´ ì¸ì§€ ëŠ¥ë ¥ì´ ë–¨ì–´ì§‘ë‹ˆë‹¤.\n",
      "\n",
      "ğŸŒ± ê´€ê³„ë§ºê¸° ì–´ë ¤ì›€: ìíì„± ì¥ì•  ğŸ’¡\n",
      "ìíì„± ì¥ì• ëŠ” ì‚¬íšŒì  ìƒí˜¸ì‘ìš©, ì˜ì‚¬ì†Œí†µ ë° ì œí•œëœ ê´€ì‹¬ì‚¬ì™€ ë°˜ë³µì ì¸ í–‰ë™ì„ íŠ¹ì§•ìœ¼ë¡œ í•©ë‹ˆë‹¤. ì´ ì¥ì• ë¥¼ ê°€ì§„ ì‚¬ëŒë“¤ì€ ê´€ê³„ë¥¼ í˜•ì„±í•˜ê³  ìœ ì§€í•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸŒ± ì†Œí†µì˜ ì–´ë ¤ì›€: ì •ì‹ ì¥ì•  ğŸ’¡\n",
      "ì •ì‹ ì¥ì• ëŠ” ìƒê°, ê°ì • ë˜ëŠ” í–‰ë™ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë‹¤ì–‘í•œ ì¥ì• ë¡œ, ì¡°í˜„ë³‘ê³¼ ê¸°ë¶„ì¥ì•  ë“±ì´ í¬í•¨ë©ë‹ˆë‹¤. ì´ ì¥ì• ë¥¼ ê°€ì§„ ì‚¬ëŒë“¤ì€ ìƒê°ê³¼ ê°ì •ì„ íš¨ê³¼ì ìœ¼ë¡œ ì†Œí†µí•˜ëŠ” ë° ì–´ë ¤ì›€ì„ ê²ªìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸŒˆ ì¥ì•  ë“±ê¸‰ ê¸°ì¤€ ì´í•´ì™€ í•¨ê»˜ ë” ë‚˜ì€ ì„¸ìƒì„ ë§Œë“¤ì–´ê°€ìš”! ğŸŒ\n"
     ]
    }
   ],
   "source": [
    "# Chain ì‹¤í–‰\n",
    "query = \"ì¥ì•  ë“±ê¸‰ ê¸°ì¤€\"\n",
    "answer = rag_chain.invoke(query)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
